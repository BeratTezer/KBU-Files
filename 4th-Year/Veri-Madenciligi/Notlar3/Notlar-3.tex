\documentclass[12pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[turkish]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{geometry}
\geometry{a4paper, margin=1in}

\title{Çalışma Notları: Kümeleme Analizi: Temel Kavramlar ve Yöntemler (Bölüm 10)}
\date{\today}

\begin{document}
	
	\maketitle
	
	\section{Bölüm 10: Kümeleme Analizi: Temel Kavramlar ve Yöntemler}
	
	\subsection{Kümeleme Analizi (Cluster Analysis)}
	\subsubsection{Kümeleme Analizi Nedir? (Sayfa 444)}
	\textbf{Kümeleme} (Clustering), nesneleri, bir küme içindeki nesnelerin birbirine benzeyeceği, ancak diğer kümelerdeki nesnelerden farklı olacağı şekilde gruplara ayıran bir \textbf{denetimsiz öğrenme} (unsupervised learning) görevidir [1-4].
	\begin{itemize}
		\item \textbf{Amaç:} Kümeleme, \textbf{sınıf etiketlerine bakılmaksızın} veri nesnelerini analiz eder ve verilerdeki doğal grupları veya \textbf{içsel olarak türetilmiş kategorileri} belirlemek için kullanılır [2, 3, 5, 6].
		\item \textbf{Ayırma Tipi:} Temel kümeleme yöntemleri genellikle \textbf{özel küme ayırmayı} (exclusive cluster separation) benimser; yani her nesne tam olarak bir gruba ait olmalıdır. Bu gereklilik, bulanık bölümleme (fuzzy partitioning) gibi tekniklerle esnetilebilir [7].
	\end{itemize}
	
	\subsubsection{Temel Kümeleme Yöntemlerine Genel Bakış (Sayfa 448)}
	Temel kümeleme yöntemleri dört ana kategoriye ayrılır:
	\begin{itemize}
		\item \textbf{Bölümleme Yöntemleri (Partitioning Methods):} Veri kümesini $k$ parçaya böler. $k$-means ve $k$-medoids gibi yöntemler, küçük-orta boyutlu veri setlerinde \textbf{küresel şekilli} kümeleri bulmak için iyi çalışır [7-9].
		\item \textbf{Hiyerarşik Yöntemler (Hierarchical Methods):} Nesneleri bir hiyerarşi içinde düzenler, ya aşağıdan yukarıya (\textbf{kümelemeli} / agglomerative) ya da yukarıdan aşağıya (\textbf{bölücü} / divisive) strateji kullanır [4, 10].
		\item \textbf{Yoğunluk Tabanlı Yöntemler (Density-Based Methods):} Küme olmayan seyrek bölgelerle ayrılmış \textbf{yoğun bölgeler} olarak kümeleri modeller. Bu, \textbf{keyfi şekilli} (arbitrary shape) kümelerin keşfedilmesini sağlar [4, 11].
		\item \textbf{Izgara Tabanlı Yöntemler (Grid-Based Methods):} Nesne uzayını bir ızgara yapısına ayırır. Temel avantajı, işlem süresinin genellikle \textbf{nesne sayısından bağımsız} olmasıdır, sadece ızgaradaki hücre sayısına bağlıdır [12].
	\end{itemize}
	
	\subsection{Bölümleme Yöntemleri (Partitioning Methods) (Sayfa 451)}
	Bölümleme, nesneleri $k$ exclusive gruba (kümelere) ayırır [13].
	
	\subsubsection{k-Means: Merkez Tabanlı Bir Teknik (Sayfa 451)}
	$k$-Means, $k$ sayısını önceden girdi olarak alır ve küme merkezlerini hesaplamak için \textbf{ortalama} (mean) kullanır [9].
	
	\subsubsection{k-Medoids: Temsilci Nesne Tabanlı Bir Teknik (Sayfa 454)}
	$k$-Medoids, kümeyi temsil etmek için kümenin \textbf{medoid'ini} (küme içindeki en merkezi nesneyi) kullanır [9].
	\begin{itemize}
		\item \textbf{PAM (Partitioning Around Medoids):} Tüm veri setini inceleyerek en iyi $k$ medoid'i bulmaya çalışır.
		\item \textbf{CLARA ve CLARANS:} Büyük veri setleri için, \textbf{rastgele örnekler} (random samples) kullanarak performans artışı sağlayan $k$-medoids yöntemleridir [14].
	\end{itemize}
	
	\subsection{Hiyerarşik Yöntemler (Hierarchical Methods) (Sayfa 457)}
	
	Hiyerarşik yöntemler, nesneleri, ya \textbf{kümelemeli} (bottom-up) ya da \textbf{bölücü} (top-down) bir strateji kullanarak hiyerarşik bir düzende düzenler [4, 10].
	
	\subsubsection{Kümelemeliye Karşı Bölücü Hiyerarşik Kümeleme (Sayfa 459)}
	\begin{itemize}
		\item \textbf{Kümelemeli (Agglomerative):} Her nesnenin ayrı bir küme olarak başladığı ve birbirine \textbf{en yakın} (en benzer) küme çiftlerinin yinelemeli olarak \textbf{birleştirildiği} yöntemdir [10].
		\item \textbf{Bölücü (Divisive):} Tüm nesnelerin tek bir kümede toplandığı yerden başlar ve kümeyi yinelemeli olarak \textbf{böler} (split) [10]. \textbf{DIANA} bu yönteme örnektir [10].
	\end{itemize}
	\textbf{Bağlantı Türleri (Linkages):} Küme yakınlığını ölçmek için farklı stratejiler kullanılır:
	\begin{itemize}
		\item \textbf{Tek Bağlantı (Single Linkage):} Yerel yakınlığa dayalı kümeler bulur [15].
		\item \textbf{Tam Bağlantı (Complete Linkage):} Küresel yakınlığı tercih eden kümeler bulma eğilimindedir [15].
	\end{itemize}
	
	\subsubsection{Probabilistik Hiyerarşik Kümeleme (Sayfa 467)}
	Bu şemada, birleştirme işlemi \textbf{maksimum olabilirlik} (maximum likelihood) ilkesine dayanır [16].
	İki küme, $C_i$ ve $C_j$, ancak ve ancak aralarındaki mesafe (veya küme kalitesindeki artış) pozitif ise birleştirilir. İterasyon, aşağıdaki logaritmik değer pozitif olduğu sürece devam eder:
	$$ \log \frac{P(C_i \cup C_j)}{P(C_i)P(C_j)} > 0 $$
	Bu, küme kalitesinde bir iyileşme olduğunu gösterir [17, 18].
	
	\subsection{Yoğunluk Tabanlı Yöntemler (Density-Based Methods) (Sayfa 471)}
	
	Bu yöntemler, bölümleme ve hiyerarşik yöntemlerin aksine, keyfi şekilli (nonspherical shape) kümeleri bulmak için tasarlanmıştır [11].
	
	\subsubsection{DBSCAN (Sayfa 471)}
	DBSCAN (\textbf{D}ensity-\textbf{B}ased \textbf{S}patial \textbf{C}lustering of \textbf{A}pplications with \textbf{N}oise), yüksek yoğunluğa sahip bağlı bölgelere dayanır [11].
	\begin{itemize}
		\item \textbf{Parametreler:} Bir nesnenin komşuluğunu tanımlamak için \textbf{$\epsilon$} (epsilon) ve yoğunluk eşiğini belirlemek için \textbf{MinPts} kullanılır [19, 20].
		\item \textbf{Çekirdek Nesne (Core Object):} $\epsilon$-komşuluğu içinde en az $MinPts$ nesnesi bulunan nesnedir [20].
	\end{itemize}
	
	\subsubsection{OPTICS (Sayfa 474)}
	OPTICS, tek bir $\epsilon$ ve $MinPts$ parametre seti kullanmanın zorluğunu aşmak için önerilmiştir [21].
	\begin{itemize}
		\item \textbf{Çıktı:} Veri kümesinin kümeleme yapısını temsil eden, bir \textbf{küme sıralaması} (cluster ordering) çıktısı verir; bu, çeşitli parametre ayarlarından elde edilen yoğunluk tabanlı kümelemeye eşdeğerdir [21, 22].
		\item \textbf{Mesafe Ölçüleri:} \textbf{Çekirdek Mesafesi} (Core-distance) ve \textbf{Erişilebilirlik Mesafesi} (Reachability-distance) kavramlarını kullanır [23].
	\end{itemize}
	
	\subsubsection{DENCLUE (Sayfa 477)}
	DENCLUE, yoğunluğu tahmin etmek için \textbf{Gaussian çekirdeği} (kernel) gibi çekirdek fonksiyonları kullanır [24].
	\begin{itemize}
		\item \textbf{Yoğunluk Çekicileri (Density Attractors):} Tahmin edilen yoğunluk fonksiyonunun yerel maksimumlarıdır ($x^*$). Yalnızca yoğunluk eşiği $\xi$'yi aşan çekiciler dikkate alınır [24].
		\item \textbf{İşleyiş:} Nesneler, aşamalı bir tepe tırmanma (hill-climbing) prosedürü kullanarak yoğunluk çekicilerine atanır [24, 25].
	\end{itemize}
	
	\subsection{Izgara Tabanlı Yöntemler (Grid-Based Methods) (Sayfa 479)}
	
	Izgara tabanlı yöntemler, nesne uzayını ızgara hücrelerine ayırır ve kümeleme işlemlerini bu nicelleştirilmiş uzayda gerçekleştirir [12].
	
	\subsubsection{STING (Sayfa 479)}
	STING (\textbf{ST}atistical \textbf{IN}formation \textbf{G}rid), \textbf{çok çözünürlüklü bir ızgara veri yapısı} kullanır [13].
	\begin{itemize}
		\item \textbf{Hiyerarşi:} Yüksek seviye hücrelerin istatistiksel parametreleri (sayım, ortalama, standart sapma, min, max, dağılım tipi) alt seviye hücrelerden kolayca hesaplanabilir [26].
	\end{itemize}
	
	\subsubsection{CLIQUE (Sayfa 481)}
	CLIQUE (\textbf{CL}ustering \textbf{I}n \textbf{QUE}st), alt uzaylarda (subspaces) yoğunluk tabanlı kümeler bulmak için Apriori özelliğinin \textbf{monotonluğunu} kullanır [27].
	\begin{itemize}
		\item \textbf{İşleyiş:} Her boyutu bölümlere ayırarak hücreler oluşturur ve yoğun hücreleri belirlemek için bir yoğunluk eşiği kullanır. $k$-boyutlu bir hücre, her $(k-1)$-boyutlu izdüşümü de yoğun ise en az $l$ noktaya sahip olabilir [27].
		\item \textbf{Küme Oluşturma:} Maksimal bölgeler (maximal regions) kullanılarak, birbirine bağlı yoğun hücreler birleştirilerek keyfi şekilli kümeler oluşturulur [28].
	\end{itemize}
	
	\subsection{Kümeleme Değerlendirmesi (Evaluation of Clustering) (Sayfa 483)}
	
	Kümeleme değerlendirmesi, kümeleme analizinin uygulanabilirliğini ve sonuçların kalitesini ölçer.
	
	\subsubsection{Kümeleme Eğilimini Değerlendirme (Assessing Clustering Tendency) (Sayfa 484)}
	\textbf{Amaç:} Veride rastgele olmayan (non-random) bir yapının (anlamlı kümelerin) var olup olmadığını belirlemektir [29, 30].
	\begin{itemize}
		\item \textbf{Hopkins İstatistiği:} Veri kümesinin tek tip (uniform) dağılıp dağılmadığını test etmek için kullanılır [31]. Eğer $H > 0.5$ ise, veri kümesinde istatistiksel olarak anlamlı kümeler bulunması \textbf{düşüktür} [31].
	\end{itemize}
	
	\subsubsection{Küme Sayısının Belirlenmesi (Determining the Number of Clusters) (Sayfa 486)}
	Küme sayısını belirlemek için, sınıflandırmada da kullanılan \textbf{çapraz doğrulama} (cross-validation) tekniği kullanılabilir. Farklı $k$ değerleri için kümeleme modeli kalitesi karşılaştırılır [32].
	
	\subsubsection{Kümeleme Kalitesini Ölçme (Measuring Clustering Quality) (Sayfa 487)}
	Kümeleme kalitesi, İçsel (Intrinsic, sadece veri setine dayalı) veya Dışsal (Extrinsic, zemin gerçekliğine/ground truth'a dayalı) yöntemlerle ölçülür. Dışsal ölçümler için temel gereksinimler:
	\begin{itemize}
		\item \textbf{Küme Homojenliği (Cluster Homogeneity):} Aynı zemin gerçekliği kategorisine ait nesnelerin aynı kümede toplanması gerekir [33].
		\item \textbf{Küme Tamlığı (Cluster Completeness):} Aynı zemin gerçekliği kategorisine ait tüm nesnelerin aynı kümeye atanması gerekir [33].
		\item \textbf{BCubed Metrikleri:} Dışsal kümeleme değerlendirmesi için kullanılan ölçü türlerindendir (Örn: BCubed Precision) [34].
	\end{itemize}
	
	\subsection{Özet (Summary) (Sayfa 490)}
	Kümeleme, verilerdeki latent (gizli) kategorileri bulmak için kullanılan bir denetimsiz öğrenme yöntemidir [4, 5]. Temel yöntemler arasında \textbf{bölümleme}, \textbf{hiyerarşik}, \textbf{yoğunluk tabanlı} ve \textbf{ızgara tabanlı} yöntemler bulunur [4]. Bir kümeleme yönteminin \textbf{ölçeklenebilirlik}, \textbf{keyfi küme şekilleriyle başa çıkma} ve \textbf{gürültüye karşı insansızlık} gibi gereksinimleri karşılaması beklenir [4].
\end{document}